{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 01:34:30.266655: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-05 01:34:31.589140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2025-02-05 01:34:31.589233: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2025-02-05 01:34:31.589240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 설정 완료: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "데이터셋의 크기: (100603, 2)\n",
      "컬럼명: Index(['features_json', 'Reason'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import tensorflow as tf\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU 설정 완료:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# 데이터베이스 연결 함수\n",
    "def get_db():\n",
    "    db = pymysql.connect(\n",
    "        host='human-mysql.mysql.database.azure.com',  # Azure MySQL Host\n",
    "        port=3306,  # Port number (MySQL default is 3306)\n",
    "        user='human',  # Username\n",
    "        passwd='!q1w2e3r4',  # Password\n",
    "        db='humandb',  # Database name\n",
    "        ssl_ca=r'/home/azureuser/Desktop/config/DigiCertGlobalRootG2.crt.pem'  # SSL certificate path\n",
    "    )\n",
    "    return db\n",
    "\n",
    "# DB에서 데이터 로드\n",
    "db_connection = get_db()\n",
    "cursor = db_connection.cursor()\n",
    "\n",
    "query = \"SELECT * FROM humandb.modeling_retrival\"\n",
    "cursor.execute(query)\n",
    "columns = [desc[0] for desc in cursor.description]  # 컬럼 이름 가져오기\n",
    "all_data = cursor.fetchall()  # 데이터 가져오기\n",
    "\n",
    "# Pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "# 데이터 확인\n",
    "print(\"데이터셋의 크기:\", df.shape)\n",
    "print(\"컬럼명:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(x):\n",
    "    if isinstance(x, str):  # JSON이 문자열로 저장된 경우 변환\n",
    "        return json.loads(x)\n",
    "    return x  # 이미 리스트 형식이라면 그대로 반환\n",
    "\n",
    "df[\"features_vector\"] = df[\"features_json\"].apply(parse_json)\n",
    "\n",
    "# features_json 컬럼 삭제 (벡터 리스트만 유지)\n",
    "df = df.drop(columns=[\"features_json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100603 entries, 0 to 100602\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   Reason           100603 non-null  object\n",
      " 1   features_vector  100603 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason</th>\n",
       "      <th>features_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>특이사항 없음으로 일상 상황으로 판단</td>\n",
       "      <td>[73.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>특이사항 없음으로 일상 상황으로 판단</td>\n",
       "      <td>[73.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>특이사항 없음으로 일상 상황으로 판단</td>\n",
       "      <td>[73.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>특이사항 없음으로 일상 상황으로 판단</td>\n",
       "      <td>[74.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>특이사항 없음으로 일상 상황으로 판단</td>\n",
       "      <td>[74.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Reason                                    features_vector\n",
       "0  특이사항 없음으로 일상 상황으로 판단  [73.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10...\n",
       "1  특이사항 없음으로 일상 상황으로 판단  [73.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0....\n",
       "2  특이사항 없음으로 일상 상황으로 판단  [73.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0....\n",
       "3  특이사항 없음으로 일상 상황으로 판단  [74.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0....\n",
       "4  특이사항 없음으로 일상 상황으로 판단  [74.0, 16.0, 98.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0...."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도(Accuracy): 0.82\n",
      "정밀도(Precision): 0.19\n",
      "재현율(Recall): 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/anaconda3/envs/emergency/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋을 학습용(80%)과 테스트용(20%)으로 분할\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# FAISS 인덱스 생성 (L2 거리 기반)\n",
    "vector_data = np.array(train_df[\"features_vector\"].tolist(), dtype=np.float32)\n",
    "index = faiss.IndexFlatL2(vector_data.shape[1])\n",
    "index.add(vector_data)\n",
    "\n",
    "# 테스트 데이터 검색\n",
    "test_vectors = np.array(test_df[\"features_vector\"].tolist(), dtype=np.float32)\n",
    "true_labels = test_df[\"Reason\"].tolist()\n",
    "\n",
    "# FAISS 검색 (Top-1)\n",
    "_, nearest = index.search(test_vectors, 1)\n",
    "\n",
    "# 검색된 Reason 값 가져오기\n",
    "retrieved_reasons = [train_df.iloc[i][\"Reason\"] for i in nearest.flatten()]\n",
    "\n",
    "# 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 계산\n",
    "accuracy = accuracy_score(true_labels, retrieved_reasons)\n",
    "precision = precision_score(true_labels, retrieved_reasons, average=\"macro\")\n",
    "recall = recall_score(true_labels, retrieved_reasons, average=\"macro\")\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"정확도(Accuracy): {accuracy:.2f}\")\n",
    "print(f\"정밀도(Precision): {precision:.2f}\")\n",
    "print(f\"재현율(Recall): {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reason\n",
      "특이사항 없음으로 일상 상황으로 판단               78803\n",
      "분당 호흡, 혈중산소농도 등 기준으로 주의 상황으로 판단    78803\n",
      "피부온도변화, 응급버튼 기준으로 위험 상황으로 판단       78803\n",
      "혈중산소농도 기준으로 위험 상황으로 판단             78803\n",
      "응급음성 기준으로 위험 상황으로 판단               78803\n",
      "응급버튼 기준으로 위험 상황으로 판단               78803\n",
      "분당 심박, 피부온도변화 기준으로 위험 상황으로 판단      78803\n",
      "분당 호흡, 피부온도변화 기준으로 위험 상황으로 판단      78803\n",
      "분당 심박, 혈중산소농도 등 기준으로 주의 상황으로 판단    78803\n",
      "분당 심박, 피부온도변화 등 기준으로 주의 상황으로 판단    78803\n",
      "분당 심박 기준으로 위험 상황으로 판단              78803\n",
      "분당 심박, 분당 호흡 등 기준으로 위험 상황으로 판단     78803\n",
      "분당 심박, 분당 호흡 기준으로 위험 상황으로 판단       78803\n",
      "분당 심박, 혈중산소농도 기준으로 주의 상황으로 판단      78803\n",
      "분당 심박, 분당 호흡 등 기준으로 주의 상황으로 판단     78803\n",
      "혈중산소농도, 피부온도변화 기준으로 주의 상황으로 판단     78803\n",
      "분당 심박, 피부온도변화 기준으로 주의 상황으로 판단      78803\n",
      "피부온도변화 기준으로 위험 상황으로 판단             78803\n",
      "피부온도변화 기준으로 주의 상황으로 판단             78803\n",
      "혈중산소농도 기준으로 주의 상황으로 판단             78803\n",
      "분당 호흡, 혈중산소농도 기준으로 주의 상황으로 판단      78803\n",
      "분당 호흡 기준으로 주의 상황으로 판단              78803\n",
      "분당 호흡, 피부온도변화 기준으로 주의 상황으로 판단      78803\n",
      "분당 호흡 기준으로 위험 상황으로 판단              78803\n",
      "분당 심박 기준으로 주의 상황으로 판단              78803\n",
      "분당 심박, 분당 호흡 기준으로 주의 상황으로 판단       78803\n",
      "분당 심박, 혈중산소농도 기준으로 위험 상황으로 판단      78803\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 올바른 import 방식\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 특정 클래스를 제거 (샘플 개수가 5개 이하인 클래스 삭제)\n",
    "min_samples_required = 2\n",
    "filtered_df = df[df.groupby(\"Reason\")[\"Reason\"].transform(\"count\") >= min_samples_required]\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(sampling_strategy=\"auto\", random_state=42, k_neighbors=1)\n",
    "X_resampled, y_resampled = smote.fit_resample(np.array(filtered_df[\"features_vector\"].tolist()), filtered_df[\"Reason\"])\n",
    "\n",
    "# 최종 균형 잡힌 데이터 생성\n",
    "final_df = pd.DataFrame({\"features_vector\": X_resampled.tolist(), \"Reason\": y_resampled})\n",
    "\n",
    "print(final_df[\"Reason\"].value_counts())  # 클래스 분포 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reason\n",
      "분당 심박 기준으로 위험 상황으로 판단              15000\n",
      "분당 호흡, 피부온도변화 기준으로 위험 상황으로 판단      15000\n",
      "혈중산소농도 기준으로 주의 상황으로 판단             15000\n",
      "혈중산소농도 기준으로 위험 상황으로 판단             15000\n",
      "피부온도변화, 응급버튼 기준으로 위험 상황으로 판단       15000\n",
      "피부온도변화 기준으로 주의 상황으로 판단             15000\n",
      "피부온도변화 기준으로 위험 상황으로 판단             15000\n",
      "특이사항 없음으로 일상 상황으로 판단               15000\n",
      "응급음성 기준으로 위험 상황으로 판단               15000\n",
      "응급버튼 기준으로 위험 상황으로 판단               15000\n",
      "분당 호흡, 혈중산소농도 등 기준으로 주의 상황으로 판단    15000\n",
      "분당 호흡, 혈중산소농도 기준으로 주의 상황으로 판단      15000\n",
      "분당 호흡, 피부온도변화 기준으로 주의 상황으로 판단      15000\n",
      "분당 호흡 기준으로 주의 상황으로 판단              15000\n",
      "분당 심박 기준으로 주의 상황으로 판단              15000\n",
      "분당 호흡 기준으로 위험 상황으로 판단              15000\n",
      "분당 심박, 혈중산소농도 등 기준으로 주의 상황으로 판단    15000\n",
      "분당 심박, 혈중산소농도 기준으로 주의 상황으로 판단      15000\n",
      "분당 심박, 혈중산소농도 기준으로 위험 상황으로 판단      15000\n",
      "분당 심박, 피부온도변화 등 기준으로 주의 상황으로 판단    15000\n",
      "분당 심박, 피부온도변화 기준으로 주의 상황으로 판단      15000\n",
      "분당 심박, 피부온도변화 기준으로 위험 상황으로 판단      15000\n",
      "분당 심박, 분당 호흡 등 기준으로 주의 상황으로 판단     15000\n",
      "분당 심박, 분당 호흡 등 기준으로 위험 상황으로 판단     15000\n",
      "분당 심박, 분당 호흡 기준으로 주의 상황으로 판단       15000\n",
      "분당 심박, 분당 호흡 기준으로 위험 상황으로 판단       15000\n",
      "혈중산소농도, 피부온도변화 기준으로 주의 상황으로 판단     15000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 각 클래스별 최대 10,000개만 유지\n",
    "max_samples_per_class = 15000\n",
    "df_sampled = final_df.groupby(\"Reason\").apply(lambda x: x.sample(n=min(len(x), max_samples_per_class), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# 샘플링 후 클래스 분포 확인\n",
    "print(df_sampled[\"Reason\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도(Accuracy): 0.9912\n",
      "정밀도(Precision): 0.9912\n",
      "재현율(Recall): 0.9910\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# 데이터셋을 학습용(80%)과 테스트용(20%)으로 분할\n",
    "train_df, test_df = train_test_split(df_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# FAISS CPU 인덱스 생성\n",
    "vector_data = np.array(train_df[\"features_vector\"].tolist(), dtype=np.float32)\n",
    "\n",
    "# CPU에서 FAISS 실행 (메모리 부족 방지)\n",
    "cpu_index = faiss.IndexFlatL2(vector_data.shape[1])\n",
    "cpu_index.add(vector_data)\n",
    "\n",
    "# 테스트 데이터 검색\n",
    "test_vectors = np.array(test_df[\"features_vector\"].tolist(), dtype=np.float32)\n",
    "true_labels = test_df[\"Reason\"].tolist()\n",
    "\n",
    "# FAISS 검색 (Top-1 검색)\n",
    "_, nearest = cpu_index.search(test_vectors, 1)\n",
    "\n",
    "# 검색된 Reason 값 가져오기\n",
    "retrieved_reasons = [train_df.iloc[i][\"Reason\"] for i in nearest.flatten()]\n",
    "\n",
    "# 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 계산\n",
    "accuracy = accuracy_score(true_labels, retrieved_reasons)\n",
    "precision = precision_score(true_labels, retrieved_reasons, average=\"macro\")\n",
    "recall = recall_score(true_labels, retrieved_reasons, average=\"macro\")\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"정확도(Accuracy): {accuracy:.4f}\")\n",
    "print(f\"정밀도(Precision): {precision:.4f}\")\n",
    "print(f\"재현율(Recall): {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터와 테스트 데이터의 중복 개수: 0\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터가 중복되는지 확인\n",
    "duplicate_count = test_df[test_df.index.isin(train_df.index)].shape[0]\n",
    "\n",
    "print(f\"훈련 데이터와 테스트 데이터의 중복 개수: {duplicate_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 클래스 분포:\n",
      "Reason\n",
      "분당 호흡, 혈중산소농도 등 기준으로 주의 상황으로 판단    0.037386\n",
      "분당 심박 기준으로 주의 상황으로 판단              0.037370\n",
      "분당 심박, 피부온도변화 등 기준으로 주의 상황으로 판단    0.037238\n",
      "피부온도변화, 응급버튼 기준으로 위험 상황으로 판단       0.037182\n",
      "특이사항 없음으로 일상 상황으로 판단               0.037179\n",
      "분당 호흡, 피부온도변화 기준으로 위험 상황으로 판단      0.037176\n",
      "분당 호흡, 피부온도변화 기준으로 주의 상황으로 판단      0.037151\n",
      "피부온도변화 기준으로 주의 상황으로 판단             0.037127\n",
      "분당 심박, 분당 호흡 등 기준으로 위험 상황으로 판단     0.037108\n",
      "응급버튼 기준으로 위험 상황으로 판단               0.037108\n",
      "혈중산소농도, 피부온도변화 기준으로 주의 상황으로 판단     0.037086\n",
      "분당 심박, 분당 호흡 기준으로 주의 상황으로 판단       0.037068\n",
      "분당 호흡 기준으로 위험 상황으로 판단              0.037049\n",
      "응급음성 기준으로 위험 상황으로 판단               0.037003\n",
      "혈중산소농도 기준으로 위험 상황으로 판단             0.036997\n",
      "분당 심박 기준으로 위험 상황으로 판단              0.036994\n",
      "혈중산소농도 기준으로 주의 상황으로 판단             0.036991\n",
      "분당 심박, 혈중산소농도 등 기준으로 주의 상황으로 판단    0.036988\n",
      "분당 심박, 혈중산소농도 기준으로 위험 상황으로 판단      0.036951\n",
      "분당 심박, 분당 호흡 기준으로 위험 상황으로 판단       0.036948\n",
      "분당 호흡 기준으로 주의 상황으로 판단              0.036932\n",
      "분당 호흡, 혈중산소농도 기준으로 주의 상황으로 판단      0.036914\n",
      "분당 심박, 피부온도변화 기준으로 위험 상황으로 판단      0.036877\n",
      "분당 심박, 피부온도변화 기준으로 주의 상황으로 판단      0.036849\n",
      "분당 심박, 분당 호흡 등 기준으로 주의 상황으로 판단     0.036843\n",
      "피부온도변화 기준으로 위험 상황으로 판단             0.036765\n",
      "분당 심박, 혈중산소농도 기준으로 주의 상황으로 판단      0.036722\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " Test 데이터 클래스 분포:\n",
      "Reason\n",
      "분당 심박, 혈중산소농도 기준으로 주의 상황으로 판단      0.038296\n",
      "피부온도변화 기준으로 위험 상황으로 판단             0.038123\n",
      "분당 심박, 분당 호흡 등 기준으로 주의 상황으로 판단     0.037815\n",
      "분당 심박, 피부온도변화 기준으로 주의 상황으로 판단      0.037790\n",
      "분당 심박, 피부온도변화 기준으로 위험 상황으로 판단      0.037679\n",
      "분당 호흡, 혈중산소농도 기준으로 주의 상황으로 판단      0.037531\n",
      "분당 호흡 기준으로 주의 상황으로 판단              0.037457\n",
      "분당 심박, 분당 호흡 기준으로 위험 상황으로 판단       0.037395\n",
      "분당 심박, 혈중산소농도 기준으로 위험 상황으로 판단      0.037383\n",
      "분당 심박, 혈중산소농도 등 기준으로 주의 상황으로 판단    0.037235\n",
      "혈중산소농도 기준으로 주의 상황으로 판단             0.037222\n",
      "분당 심박 기준으로 위험 상황으로 판단              0.037210\n",
      "혈중산소농도 기준으로 위험 상황으로 판단             0.037198\n",
      "응급음성 기준으로 위험 상황으로 판단               0.037173\n",
      "분당 호흡 기준으로 위험 상황으로 판단              0.036988\n",
      "분당 심박, 분당 호흡 기준으로 주의 상황으로 판단       0.036914\n",
      "혈중산소농도, 피부온도변화 기준으로 주의 상황으로 판단     0.036840\n",
      "응급버튼 기준으로 위험 상황으로 판단               0.036753\n",
      "분당 심박, 분당 호흡 등 기준으로 위험 상황으로 판단     0.036753\n",
      "피부온도변화 기준으로 주의 상황으로 판단             0.036679\n",
      "분당 호흡, 피부온도변화 기준으로 주의 상황으로 판단      0.036580\n",
      "분당 호흡, 피부온도변화 기준으로 위험 상황으로 판단      0.036481\n",
      "특이사항 없음으로 일상 상황으로 판단               0.036469\n",
      "피부온도변화, 응급버튼 기준으로 위험 상황으로 판단       0.036457\n",
      "분당 심박, 피부온도변화 등 기준으로 주의 상황으로 판단    0.036235\n",
      "분당 심박 기준으로 주의 상황으로 판단              0.035704\n",
      "분당 호흡, 혈중산소농도 등 기준으로 주의 상황으로 판단    0.035642\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터의 클래스 분포 확인\n",
    "print(\"Train 데이터 클래스 분포:\")\n",
    "print(train_df[\"Reason\"].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n Test 데이터 클래스 분포:\")\n",
    "print(test_df[\"Reason\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# PCA 적용 (예: 10차원 → 5차원)\n",
    "pca = PCA(n_components=5, random_state=42)\n",
    "train_vectors_pca = pca.fit_transform(vector_data)\n",
    "test_vectors_pca = pca.transform(test_vectors)\n",
    "\n",
    "# FAISS가 처리할 수 있도록 NumPy 배열을 C-contiguous로 변환\n",
    "train_vectors_pca = np.ascontiguousarray(train_vectors_pca, dtype=np.float32)\n",
    "test_vectors_pca = np.ascontiguousarray(test_vectors_pca, dtype=np.float32)\n",
    "\n",
    "# FAISS에 PCA 적용된 데이터 추가\n",
    "cpu_index_pca = faiss.IndexFlatL2(train_vectors_pca.shape[1])\n",
    "cpu_index_pca.add(train_vectors_pca)  # 이제 오류 없이 실행 가능\n",
    "\n",
    "\n",
    "# 다시 검색\n",
    "_, nearest_pca = cpu_index_pca.search(test_vectors_pca, 1)\n",
    "retrieved_reasons_pca = [train_df.iloc[i][\"Reason\"] for i in nearest_pca.flatten()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도(Accuracy): 0.9763\n",
      "정밀도(Precision): 0.9762\n",
      "재현율(Recall): 0.9761\n"
     ]
    }
   ],
   "source": [
    "#  정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 계산\n",
    "accuracy = accuracy_score(true_labels, retrieved_reasons_pca)\n",
    "precision = precision_score(true_labels, retrieved_reasons_pca, average=\"macro\")\n",
    "recall = recall_score(true_labels, retrieved_reasons_pca, average=\"macro\")\n",
    "\n",
    "#  결과 출력\n",
    "print(f\"정확도(Accuracy): {accuracy:.4f}\")\n",
    "print(f\"정밀도(Precision): {precision:.4f}\")\n",
    "print(f\"재현율(Recall): {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 코사인 유사도 기반 정확도(Accuracy): 0.9907\n",
      "✅ 코사인 유사도 기반 정밀도(Precision): 0.9908\n",
      "✅ 코사인 유사도 기반 재현율(Recall): 0.9905\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# 데이터셋을 학습용(80%)과 테스트용(20%)으로 분할\n",
    "train_df, test_df = train_test_split(df_sampled, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# NumPy 배열로 변환\n",
    "vector_data = np.array(train_df[\"features_vector\"].tolist(), dtype=np.float32)\n",
    "test_vectors = np.array(test_df[\"features_vector\"].tolist(), dtype=np.float32)\n",
    "\n",
    "# L2 정규화 (코사인 유사도 사용)\n",
    "vector_data = normalize(vector_data, axis=1)  # 훈련 데이터 정규화\n",
    "test_vectors = normalize(test_vectors, axis=1)  # 테스트 데이터 정규화\n",
    "\n",
    "# FAISS 코사인 유사도 기반 인덱스 생성 (Inner Product 사용)\n",
    "cpu_index = faiss.IndexFlatIP(vector_data.shape[1])  # Inner Product (IP) 인덱스 사용\n",
    "cpu_index.add(vector_data)  # 훈련 데이터 추가\n",
    "\n",
    "# 테스트 데이터 검색 (Top-1 검색)\n",
    "_, nearest = cpu_index.search(test_vectors, 1)\n",
    "\n",
    "# 검색된 Reason 값 가져오기\n",
    "retrieved_reasons = [train_df.iloc[i][\"Reason\"] for i in nearest.flatten()]\n",
    "true_labels = test_df[\"Reason\"].tolist()\n",
    "\n",
    "# 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 계산\n",
    "accuracy = accuracy_score(true_labels, retrieved_reasons)\n",
    "precision = precision_score(true_labels, retrieved_reasons, average=\"macro\", zero_division=1)\n",
    "recall = recall_score(true_labels, retrieved_reasons, average=\"macro\", zero_division=1)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"코사인 유사도 기반 정확도(Accuracy): {accuracy:.4f}\")\n",
    "print(f\"코사인 유사도 기반 정밀도(Precision): {precision:.4f}\")\n",
    "print(f\"코사인 유사도 기반 재현율(Recall): {recall:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergency",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
