{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋의 크기: (100330, 17)\n",
      "컬럼명: Index(['Index', 'HeartRate', 'BreathRate', 'SPO2', 'SkinTemperature',\n",
      "       'SleepPhase', 'SleepScore', 'WalkingSteps', 'StressIndex',\n",
      "       'ActivityIntensity', 'CaloricExpenditure', '심박', '호흡', '피부온도', '혈중산소농도',\n",
      "       '일상', '상태'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import tensorflow as tf\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU 설정 완료:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# 데이터베이스 연결 함수\n",
    "def get_db():\n",
    "    db = pymysql.connect(\n",
    "        host='human-mysql.mysql.database.azure.com',  # Azure MySQL Host\n",
    "        port=3306,  # Port number (MySQL default is 3306)\n",
    "        user='human',  # Username\n",
    "        passwd='!q1w2e3r4',  # Password\n",
    "        db='humandb',  # Database name\n",
    "        ssl_ca=r'/home/azureuser/Desktop/config/DigiCertGlobalRootG2.crt.pem'  # SSL certificate path\n",
    "    )\n",
    "    return db\n",
    "\n",
    "# DB에서 데이터 로드\n",
    "db_connection = get_db()\n",
    "cursor = db_connection.cursor()\n",
    "\n",
    "query = \"SELECT * FROM humandb.modeling\"\n",
    "cursor.execute(query)\n",
    "columns = [desc[0] for desc in cursor.description]  # 컬럼 이름 가져오기\n",
    "all_data = cursor.fetchall()  # 데이터 가져오기\n",
    "\n",
    "# Pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"데이터셋의 크기:\", df.shape)\n",
    "print(\"컬럼명:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100330 entries, 0 to 100329\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Index               100330 non-null  int64  \n",
      " 1   HeartRate           100330 non-null  int64  \n",
      " 2   BreathRate          100330 non-null  int64  \n",
      " 3   SPO2                100330 non-null  int64  \n",
      " 4   SkinTemperature     100330 non-null  float64\n",
      " 5   SleepPhase          100330 non-null  int64  \n",
      " 6   SleepScore          100330 non-null  int64  \n",
      " 7   WalkingSteps        100330 non-null  int64  \n",
      " 8   StressIndex         100330 non-null  int64  \n",
      " 9   ActivityIntensity   100330 non-null  int64  \n",
      " 10  CaloricExpenditure  100330 non-null  int64  \n",
      " 11  심박                  100330 non-null  int64  \n",
      " 12  호흡                  100330 non-null  int64  \n",
      " 13  피부온도                100330 non-null  int64  \n",
      " 14  혈중산소농도              100330 non-null  int64  \n",
      " 15  일상                  100330 non-null  int64  \n",
      " 16  상태                  100330 non-null  int64  \n",
      "dtypes: float64(1), int64(16)\n",
      "memory usage: 13.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>BreathRate</th>\n",
       "      <th>SPO2</th>\n",
       "      <th>SkinTemperature</th>\n",
       "      <th>SleepPhase</th>\n",
       "      <th>SleepScore</th>\n",
       "      <th>WalkingSteps</th>\n",
       "      <th>StressIndex</th>\n",
       "      <th>ActivityIntensity</th>\n",
       "      <th>CaloricExpenditure</th>\n",
       "      <th>심박</th>\n",
       "      <th>호흡</th>\n",
       "      <th>피부온도</th>\n",
       "      <th>혈중산소농도</th>\n",
       "      <th>일상</th>\n",
       "      <th>상태</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  HeartRate  BreathRate  SPO2  SkinTemperature  SleepPhase  \\\n",
       "0      0         73          16    98              0.0           9   \n",
       "1      1         73          16    98              0.0           9   \n",
       "2      2         73          16    98              0.0           9   \n",
       "3      3         74          16    98              0.0           9   \n",
       "4      4         74          16    98              0.0           9   \n",
       "\n",
       "   SleepScore  WalkingSteps  StressIndex  ActivityIntensity  \\\n",
       "0           0             0            0                102   \n",
       "1           0             0            0                  0   \n",
       "2           0             0            0                  0   \n",
       "3           0             0            0                  0   \n",
       "4           0             0            0                  0   \n",
       "\n",
       "   CaloricExpenditure  심박  호흡  피부온도  혈중산소농도  일상  상태  \n",
       "0                   0   0   0     0       0   1   0  \n",
       "1                   0   0   0     0       0   1   0  \n",
       "2                   0   0   0     0       0   1   0  \n",
       "3                   0   0   0     0       0   1   0  \n",
       "4                   0   0   0     0       0   1   0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (입력 데이터) shape: (100330, 10)\n",
      "y (출력 데이터) shape: (100330, 1)\n"
     ]
    }
   ],
   "source": [
    "# 다중 라벨 컬럼 선택\n",
    "y = df[['상태']]  # 다중 라벨 대상\n",
    "\n",
    "# 입력 데이터(X) 설정\n",
    "x = df.drop(columns=['Index', '심박', '호흡', '피부온도', '혈중산소농도','일상','상태'])  # 독립 변수\n",
    "\n",
    "\n",
    "# 데이터의 shape 확인\n",
    "print(\"x (입력 데이터) shape:\", x.shape)\n",
    "print(\"y (출력 데이터) shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/anaconda3/envs/emergency/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.7881 - val_accuracy: 0.8816 - val_loss: 0.2747\n",
      "Epoch 2/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.3099 - val_accuracy: 0.8830 - val_loss: 0.2547\n",
      "Epoch 3/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.2682 - val_accuracy: 0.9209 - val_loss: 0.2051\n",
      "Epoch 4/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2321 - val_accuracy: 0.9066 - val_loss: 0.2071\n",
      "Epoch 5/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2113 - val_accuracy: 0.9369 - val_loss: 0.1588\n",
      "Epoch 6/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.1991 - val_accuracy: 0.9425 - val_loss: 0.1456\n",
      "Epoch 7/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.1845 - val_accuracy: 0.9446 - val_loss: 0.1311\n",
      "Epoch 8/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1728 - val_accuracy: 0.9565 - val_loss: 0.1121\n",
      "Epoch 9/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9303 - loss: 0.1657 - val_accuracy: 0.9549 - val_loss: 0.1096\n",
      "Epoch 10/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.1568 - val_accuracy: 0.9478 - val_loss: 0.1145\n",
      "Epoch 11/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.1536 - val_accuracy: 0.9553 - val_loss: 0.1022\n",
      "Epoch 12/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.1517 - val_accuracy: 0.9628 - val_loss: 0.0914\n",
      "Epoch 13/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.1466 - val_accuracy: 0.9527 - val_loss: 0.1074\n",
      "Epoch 14/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.1449 - val_accuracy: 0.9639 - val_loss: 0.0923\n",
      "Epoch 15/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9403 - loss: 0.1423 - val_accuracy: 0.9630 - val_loss: 0.0894\n",
      "Epoch 16/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.1392 - val_accuracy: 0.9588 - val_loss: 0.0982\n",
      "Epoch 17/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1404 - val_accuracy: 0.9650 - val_loss: 0.0866\n",
      "Epoch 18/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1329 - val_accuracy: 0.9673 - val_loss: 0.0857\n",
      "Epoch 19/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.1350 - val_accuracy: 0.9664 - val_loss: 0.0873\n",
      "Epoch 20/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1309 - val_accuracy: 0.9646 - val_loss: 0.0846\n",
      "Epoch 21/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1291 - val_accuracy: 0.9772 - val_loss: 0.0734\n",
      "Epoch 22/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1299 - val_accuracy: 0.9728 - val_loss: 0.0802\n",
      "Epoch 23/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1266 - val_accuracy: 0.9723 - val_loss: 0.0735\n",
      "Epoch 24/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.1198 - val_accuracy: 0.9783 - val_loss: 0.0719\n",
      "Epoch 25/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1222 - val_accuracy: 0.9750 - val_loss: 0.0692\n",
      "Epoch 26/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1257 - val_accuracy: 0.9784 - val_loss: 0.0670\n",
      "Epoch 27/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.1217 - val_accuracy: 0.9753 - val_loss: 0.0690\n",
      "Epoch 28/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1232 - val_accuracy: 0.9744 - val_loss: 0.0718\n",
      "Epoch 29/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1226 - val_accuracy: 0.9791 - val_loss: 0.0689\n",
      "Epoch 30/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1184 - val_accuracy: 0.9798 - val_loss: 0.0661\n",
      "Epoch 31/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.1208 - val_accuracy: 0.9713 - val_loss: 0.0701\n",
      "Epoch 32/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.1182 - val_accuracy: 0.9766 - val_loss: 0.0667\n",
      "Epoch 33/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1164 - val_accuracy: 0.9814 - val_loss: 0.0615\n",
      "Epoch 34/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.1184 - val_accuracy: 0.9740 - val_loss: 0.0695\n",
      "Epoch 35/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9534 - loss: 0.1117 - val_accuracy: 0.9783 - val_loss: 0.0663\n",
      "Epoch 36/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1144 - val_accuracy: 0.9743 - val_loss: 0.0695\n",
      "Epoch 37/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1172 - val_accuracy: 0.9807 - val_loss: 0.0615\n",
      "Epoch 38/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1150 - val_accuracy: 0.9790 - val_loss: 0.0642\n",
      "Epoch 39/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1167 - val_accuracy: 0.9760 - val_loss: 0.0705\n",
      "Epoch 40/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1159 - val_accuracy: 0.9821 - val_loss: 0.0597\n",
      "Epoch 41/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1135 - val_accuracy: 0.9737 - val_loss: 0.0663\n",
      "Epoch 42/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1118 - val_accuracy: 0.9754 - val_loss: 0.0631\n",
      "Epoch 43/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1114 - val_accuracy: 0.9705 - val_loss: 0.0714\n",
      "Epoch 44/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1123 - val_accuracy: 0.9787 - val_loss: 0.0594\n",
      "Epoch 45/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1121 - val_accuracy: 0.9797 - val_loss: 0.0635\n",
      "Epoch 46/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1076 - val_accuracy: 0.9750 - val_loss: 0.0631\n",
      "Epoch 47/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.1074 - val_accuracy: 0.9789 - val_loss: 0.0629\n",
      "Epoch 48/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.1165 - val_accuracy: 0.9698 - val_loss: 0.0717\n",
      "Epoch 49/50\n",
      "\u001b[1m2007/2007\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.1124 - val_accuracy: 0.9783 - val_loss: 0.0594\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.9765 - loss: 0.0641\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step\n",
      "테스트 손실 (Log Loss): 0.0640\n",
      "테스트 AUROC: 0.9976\n",
      "테스트 정확도 (Accuracy): 0.9769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 데이터 준비\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 신경망 모델 정의\n",
    "keras.backend.clear_session()\n",
    "input_layer = keras.layers.Input(shape=(10,))\n",
    "\n",
    "d1 = Dense(256)(input_layer)\n",
    "d1 = LeakyReLU(alpha=0.1)(d1)  # Leaky ReLU 적용\n",
    "d1 = BatchNormalization()(d1)\n",
    "d1 = Dropout(0.2)(d1)  # 첫 번째 레이어 Dropout 낮게 설정\n",
    "\n",
    "d2 = Dense(128, activation='relu')(d1)\n",
    "d2 = BatchNormalization()(d2)\n",
    "d2 = Dropout(0.3)(d2)\n",
    "\n",
    "d3 = Dense(64, activation='relu')(d2)\n",
    "d3 = BatchNormalization()(d3)\n",
    "d3 = Dropout(0.4)(d3)\n",
    "\n",
    "d4 = Dense(32, activation='relu')(d3)\n",
    "d4 = BatchNormalization()(d4)\n",
    "d4 = Dropout(0.4)(d4)\n",
    "\n",
    "output_layer = Dense(3, activation='softmax')(d4)\n",
    "\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# AdamW 옵티마이저 설정\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=0.0005, weight_decay=1e-5)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# EarlyStopping 설정\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 모델 학습 (GPU 가속 적용)\n",
    "with tf.device(\"GPU:0\"):\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[es],\n",
    "        verbose=1,\n",
    "        epochs=50\n",
    "    )\n",
    "\n",
    "# 모델 평가 (GPU 가속 적용)\n",
    "with tf.device(\"GPU:0\"):\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "# 예측값 생성 (소프트맥스 확률값 반환)\n",
    "y_pred_prob = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# 로그 손실 (Log Loss) 계산\n",
    "logloss = log_loss(y_test, y_pred_prob)\n",
    "\n",
    "# AUROC 계산 (One-vs-Rest 방식)\n",
    "y_test_oh = tf.keras.utils.to_categorical(y_test, num_classes=3)\n",
    "auroc = roc_auc_score(y_test_oh, y_pred_prob, multi_class=\"ovr\")\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"테스트 손실 (Log Loss): {logloss:.4f}\")\n",
    "print(f\"테스트 AUROC: {auroc:.4f}\")\n",
    "print(f\"테스트 정확도 (Accuracy): {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>BreathRate</th>\n",
       "      <th>SPO2</th>\n",
       "      <th>SkinTemperature</th>\n",
       "      <th>SleepPhase</th>\n",
       "      <th>SleepScore</th>\n",
       "      <th>WalkingSteps</th>\n",
       "      <th>StressIndex</th>\n",
       "      <th>ActivityIntensity</th>\n",
       "      <th>CaloricExpenditure</th>\n",
       "      <th>심박</th>\n",
       "      <th>호흡</th>\n",
       "      <th>피부온도</th>\n",
       "      <th>혈중산소농도</th>\n",
       "      <th>일상</th>\n",
       "      <th>상태</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>80</td>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>97</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>77</td>\n",
       "      <td>19</td>\n",
       "      <td>98</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>75</td>\n",
       "      <td>21</td>\n",
       "      <td>98</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100284</th>\n",
       "      <td>51539608288</td>\n",
       "      <td>78</td>\n",
       "      <td>21</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100285</th>\n",
       "      <td>51539608289</td>\n",
       "      <td>79</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100286</th>\n",
       "      <td>51539608290</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100287</th>\n",
       "      <td>51539608291</td>\n",
       "      <td>82</td>\n",
       "      <td>21</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100288</th>\n",
       "      <td>51539608292</td>\n",
       "      <td>88</td>\n",
       "      <td>22</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21526 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Index  HeartRate  BreathRate  SPO2  SkinTemperature  SleepPhase  \\\n",
       "356             356         80          24    98             -1.1           1   \n",
       "357             357         77          21    97              0.2           1   \n",
       "358             358         77          19    98              0.4           0   \n",
       "359             359         75          21    98              0.5           0   \n",
       "360             360         77          13    98              0.5           2   \n",
       "...             ...        ...         ...   ...              ...         ...   \n",
       "100284  51539608288         78          21    98             -0.8           1   \n",
       "100285  51539608289         79          16    98             -0.6           1   \n",
       "100286  51539608290         82          20    98             -0.8           2   \n",
       "100287  51539608291         82          21    98             -0.4           1   \n",
       "100288  51539608292         88          22    98             -0.3           2   \n",
       "\n",
       "        SleepScore  WalkingSteps  StressIndex  ActivityIntensity  \\\n",
       "356             72             0            0                  0   \n",
       "357             72             0            0                  0   \n",
       "358             72             0            0                  0   \n",
       "359             72             0            0                  0   \n",
       "360             72             0            0                  0   \n",
       "...            ...           ...          ...                ...   \n",
       "100284           9             0            0                  0   \n",
       "100285           9             0            0                  0   \n",
       "100286           9             0            0                  0   \n",
       "100287           9             0            0                  0   \n",
       "100288           9             0            0                  0   \n",
       "\n",
       "        CaloricExpenditure  심박  호흡  피부온도  혈중산소농도  일상  상태  \n",
       "356                      0   1   1     0       0   0   1  \n",
       "357                      0   1   1     0       0   0   1  \n",
       "358                      0   1   0     0       0   0   1  \n",
       "359                      0   1   1     0       0   0   1  \n",
       "360                      0   1   0     0       0   0   1  \n",
       "...                    ...  ..  ..   ...     ...  ..  ..  \n",
       "100284                   0   1   1     0       0   0   1  \n",
       "100285                   0   1   0     0       0   0   1  \n",
       "100286                   0   1   1     0       0   0   1  \n",
       "100287                   0   1   1     0       0   0   1  \n",
       "100288                   0   1   1     0       0   0   1  \n",
       "\n",
       "[21526 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 상태(Status) 값이 1 또는 2인 데이터만 필터링\n",
    "df_filtered = df[df[\"상태\"].isin([1, 2])]\n",
    "\n",
    "# 필터링된 데이터 출력\n",
    "from IPython.display import display\n",
    "display(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 레이블\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (입력 데이터) shape: (21526, 10)\n",
      "y (출력 데이터) shape: (21526, 4)\n"
     ]
    }
   ],
   "source": [
    "# 다중 라벨 컬럼 선택\n",
    "y = df_filtered[['심박', '호흡', '피부온도', '혈중산소농도']]  # 다중 라벨 대상\n",
    "\n",
    "# 입력 데이터(X) 설정\n",
    "x = df_filtered.drop(columns=['Index', '심박', '호흡', '피부온도', '혈중산소농도','일상','상태'])  # 독립 변수\n",
    "\n",
    "\n",
    "# 데이터의 shape 확인\n",
    "print(\"x (입력 데이터) shape:\", x.shape)\n",
    "print(\"y (출력 데이터) shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/anaconda3/envs/emergency/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2920 - auc: 0.5129 - loss: 0.8229 - val_accuracy: 0.6150 - val_auc: 0.6572 - val_loss: 0.5471\n",
      "Epoch 2/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5421 - auc: 0.5897 - loss: 0.5799 - val_accuracy: 0.6411 - val_auc: 0.7351 - val_loss: 0.4529\n",
      "Epoch 3/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6187 - auc: 0.6724 - loss: 0.4784 - val_accuracy: 0.6966 - val_auc: 0.8251 - val_loss: 0.3709\n",
      "Epoch 4/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6763 - auc: 0.7454 - loss: 0.4114 - val_accuracy: 0.7517 - val_auc: 0.8486 - val_loss: 0.3323\n",
      "Epoch 5/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7133 - auc: 0.7841 - loss: 0.3755 - val_accuracy: 0.7448 - val_auc: 0.8628 - val_loss: 0.3129\n",
      "Epoch 6/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7353 - auc: 0.8037 - loss: 0.3509 - val_accuracy: 0.7364 - val_auc: 0.8744 - val_loss: 0.2976\n",
      "Epoch 7/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7639 - auc: 0.8270 - loss: 0.3277 - val_accuracy: 0.7140 - val_auc: 0.8856 - val_loss: 0.3017\n",
      "Epoch 8/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7760 - auc: 0.8467 - loss: 0.3038 - val_accuracy: 0.7880 - val_auc: 0.9200 - val_loss: 0.2364\n",
      "Epoch 9/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7725 - auc: 0.8711 - loss: 0.2887 - val_accuracy: 0.7799 - val_auc: 0.9355 - val_loss: 0.2205\n",
      "Epoch 10/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7809 - auc: 0.8839 - loss: 0.2764 - val_accuracy: 0.7674 - val_auc: 0.9392 - val_loss: 0.2196\n",
      "Epoch 11/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7822 - auc: 0.8974 - loss: 0.2623 - val_accuracy: 0.7953 - val_auc: 0.9549 - val_loss: 0.2054\n",
      "Epoch 12/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7859 - auc: 0.9196 - loss: 0.2462 - val_accuracy: 0.8150 - val_auc: 0.9712 - val_loss: 0.1790\n",
      "Epoch 13/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7856 - auc: 0.9323 - loss: 0.2390 - val_accuracy: 0.8162 - val_auc: 0.9766 - val_loss: 0.1646\n",
      "Epoch 14/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7942 - auc: 0.9361 - loss: 0.2315 - val_accuracy: 0.7941 - val_auc: 0.9785 - val_loss: 0.1682\n",
      "Epoch 15/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7952 - auc: 0.9424 - loss: 0.2248 - val_accuracy: 0.8206 - val_auc: 0.9829 - val_loss: 0.1479\n",
      "Epoch 16/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7961 - auc: 0.9374 - loss: 0.2264 - val_accuracy: 0.7933 - val_auc: 0.9822 - val_loss: 0.1540\n",
      "Epoch 17/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7958 - auc: 0.9427 - loss: 0.2212 - val_accuracy: 0.8206 - val_auc: 0.9819 - val_loss: 0.1508\n",
      "Epoch 18/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7953 - auc: 0.9413 - loss: 0.2207 - val_accuracy: 0.8284 - val_auc: 0.9862 - val_loss: 0.1339\n",
      "Epoch 19/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7965 - auc: 0.9512 - loss: 0.2093 - val_accuracy: 0.8330 - val_auc: 0.9864 - val_loss: 0.1311\n",
      "Epoch 20/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7934 - auc: 0.9509 - loss: 0.2109 - val_accuracy: 0.8055 - val_auc: 0.9850 - val_loss: 0.1436\n",
      "Epoch 21/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7948 - auc: 0.9489 - loss: 0.2137 - val_accuracy: 0.8333 - val_auc: 0.9840 - val_loss: 0.1417\n",
      "Epoch 22/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7924 - auc: 0.9509 - loss: 0.2135 - val_accuracy: 0.8389 - val_auc: 0.9869 - val_loss: 0.1283\n",
      "Epoch 23/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8015 - auc: 0.9526 - loss: 0.2105 - val_accuracy: 0.8208 - val_auc: 0.9862 - val_loss: 0.1361\n",
      "Epoch 24/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7899 - auc: 0.9533 - loss: 0.2074 - val_accuracy: 0.8264 - val_auc: 0.9869 - val_loss: 0.1311\n",
      "Epoch 25/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8025 - auc: 0.9570 - loss: 0.1969 - val_accuracy: 0.8281 - val_auc: 0.9857 - val_loss: 0.1306\n",
      "Epoch 26/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8023 - auc: 0.9576 - loss: 0.2042 - val_accuracy: 0.8391 - val_auc: 0.9861 - val_loss: 0.1415\n",
      "Epoch 27/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8046 - auc: 0.9563 - loss: 0.1983 - val_accuracy: 0.7997 - val_auc: 0.9855 - val_loss: 0.1341\n",
      "Epoch 28/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8079 - auc: 0.9563 - loss: 0.1940 - val_accuracy: 0.8505 - val_auc: 0.9881 - val_loss: 0.1237\n",
      "Epoch 29/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8070 - auc: 0.9581 - loss: 0.2011 - val_accuracy: 0.8272 - val_auc: 0.9882 - val_loss: 0.1249\n",
      "Epoch 30/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8005 - auc: 0.9581 - loss: 0.1998 - val_accuracy: 0.8365 - val_auc: 0.9889 - val_loss: 0.1220\n",
      "Epoch 31/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8116 - auc: 0.9581 - loss: 0.1946 - val_accuracy: 0.8461 - val_auc: 0.9895 - val_loss: 0.1178\n",
      "Epoch 32/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8095 - auc: 0.9600 - loss: 0.1909 - val_accuracy: 0.8130 - val_auc: 0.9860 - val_loss: 0.1353\n",
      "Epoch 33/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8021 - auc: 0.9597 - loss: 0.1954 - val_accuracy: 0.8026 - val_auc: 0.9867 - val_loss: 0.1380\n",
      "Epoch 34/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8065 - auc: 0.9588 - loss: 0.1963 - val_accuracy: 0.8223 - val_auc: 0.9871 - val_loss: 0.1255\n",
      "Epoch 35/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8077 - auc: 0.9633 - loss: 0.1842 - val_accuracy: 0.8481 - val_auc: 0.9905 - val_loss: 0.1117\n",
      "Epoch 36/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8089 - auc: 0.9610 - loss: 0.1928 - val_accuracy: 0.8449 - val_auc: 0.9897 - val_loss: 0.1147\n",
      "Epoch 37/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8134 - auc: 0.9601 - loss: 0.1859 - val_accuracy: 0.8310 - val_auc: 0.9884 - val_loss: 0.1205\n",
      "Epoch 38/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8080 - auc: 0.9613 - loss: 0.1902 - val_accuracy: 0.8534 - val_auc: 0.9902 - val_loss: 0.1104\n",
      "Epoch 39/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8132 - auc: 0.9637 - loss: 0.1870 - val_accuracy: 0.8322 - val_auc: 0.9890 - val_loss: 0.1168\n",
      "Epoch 40/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8105 - auc: 0.9628 - loss: 0.1874 - val_accuracy: 0.8089 - val_auc: 0.9877 - val_loss: 0.1260\n",
      "Epoch 41/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8094 - auc: 0.9631 - loss: 0.1858 - val_accuracy: 0.8290 - val_auc: 0.9874 - val_loss: 0.1171\n",
      "Epoch 42/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8086 - auc: 0.9632 - loss: 0.1883 - val_accuracy: 0.8229 - val_auc: 0.9878 - val_loss: 0.1343\n",
      "Epoch 43/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8009 - auc: 0.9648 - loss: 0.1876 - val_accuracy: 0.8307 - val_auc: 0.9893 - val_loss: 0.1149\n",
      "Epoch 44/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8066 - auc: 0.9635 - loss: 0.1848 - val_accuracy: 0.8394 - val_auc: 0.9887 - val_loss: 0.1163\n",
      "Epoch 45/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8073 - auc: 0.9646 - loss: 0.1811 - val_accuracy: 0.8525 - val_auc: 0.9906 - val_loss: 0.1094\n",
      "Epoch 46/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8083 - auc: 0.9630 - loss: 0.1919 - val_accuracy: 0.8345 - val_auc: 0.9899 - val_loss: 0.1103\n",
      "Epoch 47/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8078 - auc: 0.9639 - loss: 0.1850 - val_accuracy: 0.7973 - val_auc: 0.9876 - val_loss: 0.1392\n",
      "Epoch 48/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8083 - auc: 0.9661 - loss: 0.1813 - val_accuracy: 0.8452 - val_auc: 0.9903 - val_loss: 0.1066\n",
      "Epoch 49/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8081 - auc: 0.9657 - loss: 0.1804 - val_accuracy: 0.8598 - val_auc: 0.9894 - val_loss: 0.1162\n",
      "Epoch 50/50\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8071 - auc: 0.9657 - loss: 0.1836 - val_accuracy: 0.8394 - val_auc: 0.9896 - val_loss: 0.1163\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8586 - auc: 0.9880 - loss: 0.1066  \n",
      "테스트 손실: 0.1018\n",
      "테스트 정확도: 0.8504\n",
      "테스트 AUC: 0.9911\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 준비\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 신경망 모델 정의\n",
    "keras.backend.clear_session()\n",
    "input_layer = keras.layers.Input(shape=(10,))\n",
    "\n",
    "d1 = Dense(256)(input_layer)\n",
    "d1 = LeakyReLU(alpha=0.1)(d1)  # LeakyReLU 적용 (Dying ReLU 문제 해결)\n",
    "d1 = BatchNormalization()(d1)\n",
    "d1 = Dropout(0.2)(d1)  # 첫 번째 레이어 Dropout 낮게 설정\n",
    "\n",
    "d2 = Dense(128)(d1)\n",
    "d2 = LeakyReLU(alpha=0.1)(d2)\n",
    "d2 = BatchNormalization()(d2)\n",
    "d2 = Dropout(0.3)(d2)\n",
    "\n",
    "d3 = Dense(64)(d2)\n",
    "d3 = LeakyReLU(alpha=0.1)(d3)\n",
    "d3 = BatchNormalization()(d3)\n",
    "d3 = Dropout(0.4)(d3)\n",
    "\n",
    "d4 = Dense(32)(d3)\n",
    "d4 = LeakyReLU(alpha=0.1)(d4)\n",
    "d4 = BatchNormalization()(d4)\n",
    "d4 = Dropout(0.4)(d4)\n",
    "\n",
    "output_layer = Dense(4, activation='sigmoid')(d4)\n",
    "\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# AdamW 옵티마이저 설정\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=0.0005, weight_decay=1e-5)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy', AUC(name='auc', multi_label=True)]\n",
    ")\n",
    "\n",
    "# EarlyStopping 설정 (patience 증가)\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=7,  # 조기 종료까지 기다리는 에포크 수 증가\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 모델 학습 (GPU 가속 적용)\n",
    "with tf.device(\"GPU:0\"):\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[es],\n",
    "        verbose=1,\n",
    "        epochs=50\n",
    "    )\n",
    "\n",
    "# 모델 평가 (GPU 가속 적용)\n",
    "with tf.device(\"GPU:0\"):\n",
    "    test_loss, test_accuracy, test_auc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"테스트 손실: {test_loss:.4f}\")\n",
    "print(f\"테스트 정확도: {test_accuracy:.4f}\")\n",
    "print(f\"테스트 AUC: {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설명\n",
    "\n",
    "#### y_pred > 0.5: sigmoid에서 나온 확률 값을 0/1로 변환하여 평가.\n",
    "#### Hamming Loss: 잘못 예측한 라벨의 비율 (낮을수록 좋음).\n",
    "#### F1-Score (Micro, Macro): 정밀도(Precision)와 재현율(Recall)의 균형 평가.\n",
    "#### Jaccard Score: 실제 라벨과 예측 라벨의 유사도를 평가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/135\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 64ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Hamming Loss: 0.03593822573153739\n",
      "Micro F1-Score: 0.9442091031996395\n",
      "Macro F1-Score: 0.891280896988946\n",
      "Jaccard Score: 0.9324972906022605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, jaccard_score, hamming_loss\n",
    "\n",
    "# 모델 예측 수행\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # 0.5 이상이면 1, 아니면 0\n",
    "\n",
    "# 평가 지표 계산\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred_binary))\n",
    "print(\"Micro F1-Score:\", f1_score(y_test, y_pred_binary, average='micro'))\n",
    "print(\"Macro F1-Score:\", f1_score(y_test, y_pred_binary, average='macro'))\n",
    "print(\"Jaccard Score:\", jaccard_score(y_test, y_pred_binary, average='samples'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergency",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
